<div align="center">

# ğŸ“„ Learning to Reason in 13 Parameters

**Paper Notes & Theory Reference / è®ºæ–‡ç¬”è®°ä¸ç†è®ºå‚è€ƒ**

[![Paper](https://img.shields.io/badge/arXiv-2602.04118-b31b1b)](https://arxiv.org/abs/2602.04118)
[![PDF](https://img.shields.io/badge/PDF-Local_Copy-blue)](./2602.04118v1.pdf)

[â¬… Back to Main Project / è¿”å›ä¸»é¡¹ç›®](../README.md)

</div>

---

## What is TinyLoRA? / TinyLoRA æ˜¯ä»€ä¹ˆï¼Ÿ

TinyLoRA is an extreme parameter-efficient fine-tuning method that enables language models to learn reasoning capabilities with as few as **13 trainable parameters** (26 bytes in bf16).

TinyLoRA æ˜¯ä¸€ç§æç«¯å‚æ•°é«˜æ•ˆå¾®è°ƒæ–¹æ³•ï¼Œä»…ç”¨ **13 ä¸ªå¯è®­ç»ƒå‚æ•°**ï¼ˆbf16 ä¸‹ä»… 26 å­—èŠ‚ï¼‰å°±èƒ½è®©è¯­è¨€æ¨¡å‹å­¦ä¼šæ¨ç†ã€‚

### Core Idea / æ ¸å¿ƒæ€æƒ³

$$W' = W + U \Sigma \left(\sum_{i=1}^{u} v_i P_i\right) V^\top$$

- $U, \Sigma, V$ï¼šæ¥è‡ªåŸæƒé‡ SVD åˆ†è§£çš„å†»ç»“éª¨æ¶ / Frozen skeleton from SVD of original weights
- $P_i$ï¼šå›ºå®šéšæœºæŠ•å½±çŸ©é˜µ / Fixed random projection matrices
- $v$ï¼š**å”¯ä¸€çš„å¯è®­ç»ƒå‚æ•°** / **The only trainable parameters**

---

## Key Findings / å…³é”®å‘ç°

| Finding | Details |
| :--- | :--- |
| ğŸ”¢ **13 params, 91% accuracy** | GSM8K with Qwen2.5-7B-Instruct â€” only 13 trained parameters |
| ğŸ“‰ **1000x compression** | Recovers 90% of full fine-tuning improvement with 1000x fewer params |
| ğŸ¯ **RL >> SFT** | At <100 params, SFT completely fails; only RL (GRPO) works |
| ğŸ§  **Bigger = Better** | Larger models (Qwen) are more parameter-efficient than smaller ones (LLaMA) |

---

## Why RL, Not SFT? / ä¸ºä»€ä¹ˆç”¨ RL è€Œä¸æ˜¯ SFTï¼Ÿ

| | SFT (ç›‘ç£å¾®è°ƒ) | RL (å¼ºåŒ–å­¦ä¹ ) |
| :--- | :--- | :--- |
| **å­¦ä»€ä¹ˆ** | æ¨¡ä»¿å‚è€ƒç­”æ¡ˆçš„æ ¼å¼+å†…å®¹ | åªå…³å¿ƒæœ€ç»ˆç»“æœçš„å¯¹é”™ |
| **æ‰€éœ€å®¹é‡** | é«˜ï¼ˆéœ€è®°å¿†æ ¼å¼å™ªå£°ï¼‰ | ä½ï¼ˆä»…ç¼–ç é€»è¾‘ä¿¡å·ï¼‰ |
| **æå°å‚æ•°ä¸‹** | å®Œå…¨å¤±æ•ˆ | âœ… ä¾ç„¶æœ‰æ•ˆ |

> SFT å¼ºè¿«æ¨¡å‹è®°å¿† "Noise"ï¼ˆè¡Œæ–‡é£æ ¼ã€æ ¼å¼ï¼‰ï¼ŒRL åªä¼ é€’ "Signal"ï¼ˆå¯¹/é”™ï¼‰ã€‚
> æ‰€ä»¥åœ¨ä»…æœ‰ 13 ä¸ªå‚æ•°æ—¶ï¼ŒSFT å‡†ç¡®ç‡ 83%ï¼Œè€Œ RL è¾¾åˆ° 91%ã€‚

---

## Performance Comparison / æ€§èƒ½å¯¹æ¯”

| Method | Parameters | GSM8K Accuracy |
| :--- | :---: | :---: |
| Full Fine-Tuning | 7B+ | 95% |
| LoRA (r=1) | ~3M | 94% |
| LoRA-XS (r=1) | ~100K | 93% |
| **TinyLoRA (RL)** | **13** | **91%** |
| TinyLoRA (SFT) | 13 | 83% |

---

## How We Use It / æˆ‘ä»¬å¦‚ä½•ä½¿ç”¨

æœ¬é¡¹ç›®åœ¨ TinyLoRA åŸºç¡€ä¸Šè¿›è¡Œäº†é€‚é…ï¼š

| Feature | Original Paper | Our Adaptation |
| :--- | :--- | :--- |
| **Task** | Math (GSM8K, MATH) | **Code Competitions (CodeContests)** |
| **Model** | Qwen2.5-7B / Llama-3 | **Qwen2.5-Coder-3B-Instruct** |
| **Params** | 13 ($u=13$) | **32 ($u=32$)**, adjustable |
| **Precision** | BF16 / FP32 | **4-bit NF4 + Dequant SVD** |
| **Reward** | Exact Match | **g++ Compile + Test Execution** |

---

## Further Reading / æ·±å…¥é˜…è¯»

- ğŸ“ [è¯¦ç»†ç†è®ºæ¨å¯¼ä¸å·¥ç¨‹è§£æ (explain.md)](./explain.md) â€” ä» SVD åˆ° Tiling çš„å®Œæ•´æ•°å­¦æ¨å¯¼ï¼ŒGRPO æµç¨‹ç»†èŠ‚
- ğŸ“„ [åŸè®ºæ–‡ PDF](./2602.04118v1.pdf)

---

## Citation / å¼•ç”¨

```bibtex
@article{morris2026learning,
  title={Learning to Reason in 13 Parameters},
  author={Morris, John X and Mireshghallah, Niloofar and Ibrahim, Mark and Mahloujifar, Saeed},
  journal={arXiv preprint arXiv:2602.04118},
  year={2026}
}
```

---

<div align="center">

[â¬… Back to Main Project / è¿”å›ä¸»é¡¹ç›®](../README.md)

</div>
